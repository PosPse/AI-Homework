{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label_names):\n",
    "    dataset_path = './dataset/hand-drawn-image-dataset/'\n",
    "    dataset_dict_in = {}\n",
    "    dataset_dict_out = {}\n",
    "    train_dataset_list_in, valid_dataset_list_in, test_dataset_list_in = [], [], []\n",
    "    test_dataset_list_out = []\n",
    "    for i, label_name in enumerate(label_names):\n",
    "        data = np.load(dataset_path + label_name + '/' + label_name + '.npy')\n",
    "        label = np.array([i] * len(data)).reshape(-1, 1)\n",
    "        dataset  = np.hstack((label, data))\n",
    "        if label_name in ['ambulance','apple','bear','bicycle','bird','bus','cat']:\n",
    "            dataset_dict_in[label_name] = dataset\n",
    "            train_dataset_list_in.append(dataset[:int(len(dataset)*0.7)])\n",
    "            valid_dataset_list_in.append(dataset[int(len(dataset)*0.7):int(len(dataset)*0.9)])\n",
    "            test_dataset_list_in.append(dataset[int(len(dataset)*0.9):])\n",
    "        if label_name in ['foot','owl','pig']:\n",
    "            dataset_dict_out[label_name] = dataset\n",
    "            random_idx = np.random.randint(0, len(dataset), 100)\n",
    "            test_dataset_list_out.append(dataset[random_idx])\n",
    "    train_dataset_in = np.vstack(train_dataset_list_in)\n",
    "    valid_dataset_in = np.vstack(valid_dataset_list_in)\n",
    "    test_dataset_in = np.vstack(test_dataset_list_in)\n",
    "    test_dataset_out = np.vstack(test_dataset_list_out)\n",
    "    return dataset_dict_in, dataset_dict_out, train_dataset_in, valid_dataset_in, test_dataset_in, test_dataset_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "label_names=['ambulance','apple','bear','bicycle','bird','bus','cat','foot','owl','pig']\n",
    "dataset_dict_in, dataset_dict_out, train_dataset_in, valid_dataset_in, test_dataset_in, test_dataset_out = load_data(label_names=label_names)\n",
    "train_dataset_data_in = train_dataset_in[:, 1:].reshape(-1, 28, 28)\n",
    "train_dataset_label_in = train_dataset_in[:, 0]\n",
    "valid_dataset_data_in = valid_dataset_in[:, 1:].reshape(-1, 28, 28)\n",
    "valid_dataset_label_in = valid_dataset_in[:, 0]\n",
    "test_dataset_data_in = test_dataset_in[:, 1:].reshape(-1, 28, 28)\n",
    "test_dataset_label_in = test_dataset_in[:, 0]\n",
    "test_dataset_data_out = test_dataset_out[:, 1:].reshape(-1, 28, 28)\n",
    "test_dataset_label_out = test_dataset_out[:, 0]\n",
    "print(test_dataset_data_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        super(Image_Dataset, self).__init__()\n",
    "        self.data = torch.tensor(data).float()\n",
    "        self.label = torch.tensor(label)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, label\n",
    "    \n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=0)\n",
    "        self.s2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        self.s4 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, padding=0)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.f6 = torch.nn.Linear(120, 84)\n",
    "        self.output = torch.nn.Linear(84, 10)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.conv1(x))\n",
    "        x = self.s2(x)\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        x = self.s4(x)\n",
    "        x = self.sigmoid(self.conv5(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.f6(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor()])\n",
    "train_dataset_in = Image_Dataset(train_dataset_data_in, train_dataset_label_in, transform=transform)\n",
    "valid_dataset_in = Image_Dataset(valid_dataset_data_in, valid_dataset_label_in, transform=transform)\n",
    "test_dataset_in = Image_Dataset(test_dataset_data_in, test_dataset_label_in, transform=transform)\n",
    "test_dataset_out = Image_Dataset(test_dataset_data_out, test_dataset_label_out, transform=transform)\n",
    "train_dataloader_in = DataLoader(train_dataset_in, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader_in = DataLoader(valid_dataset_in, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_in = DataLoader(test_dataset_in, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_out = DataLoader(test_dataset_out, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, train_dataloader, valid_dataloader, optimizer, criterion):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        loss = 0\n",
    "        for data_batch, label_batch in train_dataloader:\n",
    "            data_batch = data_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data_batch)\n",
    "            _loss = criterion(output, label_batch)\n",
    "            loss += _loss.item()\n",
    "            _loss.backward()\n",
    "            optimizer.step()\n",
    "        loss /= len(train_dataloader)\n",
    "        loss_list.append(loss)\n",
    "        accuracy = validate(model, valid_dataloader)\n",
    "        acc_list.append(accuracy)\n",
    "        if epoch % 2 == 0 or epoch ==  1:\n",
    "            print('device: {}, epoch: {}, loss: {:.4f}, accuracy: {:.4f}'.format(device, epoch, loss, accuracy))\n",
    "\n",
    "def validate(model, valid_dataloader):\n",
    "    correct_pred_nums = 0\n",
    "    with torch.no_grad():\n",
    "        for data_batch, label_batch in valid_dataloader:\n",
    "            data_batch = data_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            output = model(data_batch)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            correct_pred_nums += torch.sum(pred == label_batch)\n",
    "        accuracy = correct_pred_nums / len(valid_dataloader.dataset)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu, epoch: 1, loss: 1.9605, accuracy: 0.1429\n",
      "Test accuracy in: 0.1428571492433548\n",
      "Test accuracy out: 0.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "lr = 0.1\n",
    "\n",
    "lenet = LeNet().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(lenet.parameters(), lr=lr)\n",
    "train(model=lenet, epochs=epochs, train_dataloader=train_dataloader_in, valid_dataloader=valid_dataloader_in, optimizer=optimizer, criterion=criterion)\n",
    "test_accuracy_in = validate(model=lenet, valid_dataloader=test_dataloader_in)\n",
    "test_accuracy_out = validate(model=lenet, valid_dataloader=test_dataloader_out)\n",
    "print(f\"Test accuracy in: {test_accuracy_in}\")\n",
    "print(f\"Test accuracy out: {test_accuracy_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
